# For this project, I downloaded Spotify data from Kaggle.
# Then I created a table to insert Spotify data into.
# Finally, I performed analytics on the data using SQL. 

# Creating the table: 
CREATE TABLE BIT_DB.Spotifydata (
id integer PRIMARY KEY,
artist_name varchar NOT NULL,
track_name varchar NOT NULL,
track_id varchar NOT NULL,
popularity integer NOT NULL,
danceability decimal(4,3) NOT NULL,
energy decimal(4,3) NOT NULL,
key integer NOT NULL,
loudness decimal(5,3) NOT NULL,
mode integer NOT NULL,
speechiness decimal(5,4) NOT NULL,
acousticness decimal(6,5) NOT NULL,
instrumentalness text NOT NULL,
liveness decimal(5,4) NOT NULL,
valence decimal(4,3) NOT NULL,
tempo decimal(6,3) NOT NULL,
duration_ms integer NOT NULL,
time_signature integer NOT NULL 
)

# Then I inserted the Spotify Data .csv into the table.

# Next, I explored the data using the following SQL. 

# First, I determined the most popular artist.
SELECT artist_name, popularity
FROM BIT_DB.Spotifydata
GROUP BY artist_name
ORDER BY popularity DESC
LIMIT 1;


# Then I determined the top 10 songs that was most likely performed live. (above 0.6)
SELECT artist_name, track_name
FROM BIT_DB.Spotifydata
WHERE liveness > 0.6
ORDER BY liveness DESC
LIMIT 10;


# Next, I compared the overall average duration of all the tracks to the actual duration of the tracks.
SELECT track_name, duration_ms, 
(SELECT avg(duration_ms)
    FROM BIT_DB.Spotifydata) AS avg_duration
FROM BIT_DB.Spotifydata
GROUP BY track_name;


# Then I selected all tracks that are instrumentalness.
SELECT track_name
FROM BIT_DB.Spotifydata
WHERE instrumentalness > 0;


# Lastly I listed the tracks based on their valence is descending order. (Tracks with higher valence sound more positive, and tracks with lower valence sound more negative.)
SELECT track_name, valence
FROM BIT_DB.Spotifydata
ORDER BY valence DESC;
